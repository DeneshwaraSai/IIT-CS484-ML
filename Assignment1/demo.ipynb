{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Score Output\n",
      "0      35    Yes\n",
      "1      91     No\n",
      "2      52     No\n",
      "3      83     No\n",
      "4      48     No\n",
      "5      61     No\n",
      "6      40    Yes\n",
      "7      98     No\n",
      "8      73    Yes\n",
      "9      44    Yes\n",
      "10     86     No\n",
      "11     39    Yes\n",
      "12     66     No\n",
      "13     75    Yes\n",
      "14     50     No\n",
      "15     69     No\n",
      "16     70    Yes\n",
      "17     95     No\n",
      "18     80    Yes\n",
      "{0: 63.0, 5: 50.5, 6: 69.0, 7: 85.5, 9: 65.0, 10: 62.5, 11: 52.5, 12: 70.5, 13: 62.5, 15: 69.5, 16: 82.5, 17: 87.5}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Score_63.0': [1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
       " 'Score_50.5': [1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
       " 'Score_69.0': [1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0],\n",
       " 'Score_85.5': [1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1],\n",
       " 'Score_65.0': [1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
       " 'Score_62.5': [1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
       " 'Score_52.5': [1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
       " 'Score_70.5': [1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0],\n",
       " 'Score_69.5': [1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0],\n",
       " 'Score_82.5': [1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1],\n",
       " 'Score_87.5': [1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pprint\n",
    "\n",
    "eps = np.finfo(float).eps\n",
    "data=pd.read_csv(\"lab01_dataset_1.csv\")\n",
    "\n",
    "def splitPoints(data):\n",
    "    attributeDataFrame = pd.DataFrame({ 'Score' : data['Score'], 'Output' : data['Output']})\n",
    "    attributeDataFrame.reindex(np.arange(len(attributeDataFrame['Score'].index)))\n",
    "    print(attributeDataFrame)\n",
    "\n",
    "    outputvalue = attributeDataFrame['Output'][0]\n",
    "\n",
    "    splitPointDict = {}\n",
    "\n",
    "    for i in range(1, len(attributeDataFrame['Score'])):\n",
    "        if(attributeDataFrame['Output'][i] != outputvalue):\n",
    "            # (i-1) (i) mean\n",
    "            mean = (attributeDataFrame['Score'][i-1] + attributeDataFrame['Score'][i])/2\n",
    "            splitPointDict[i-1] = mean\n",
    "            outputvalue = attributeDataFrame['Output'][i]\n",
    "        \n",
    "    print(splitPointDict)\n",
    "\n",
    "    return attributeDataFrame, splitPointDict\n",
    "\n",
    "attributeDataFrame, splitPoint = splitPoints(data)\n",
    "\n",
    "columnsList = {}\n",
    "\n",
    "for i in splitPoint:\n",
    "    split = splitPoint[i]\n",
    "    # \"Score_\" + str(split)\n",
    "    scoreList=[]\n",
    "    for j in range(0, len(attributeDataFrame['Score'])):\n",
    "        if attributeDataFrame['Score'][j] < split:\n",
    "            scoreList.append(1)\n",
    "        else: \n",
    "            scoreList.append(0)\n",
    "\n",
    "    columnsList[\"Score_\" + str(split)] = scoreList\n",
    "\n",
    "columnsList\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Score': {35: 'Yes',\n",
      "           39: 'Yes',\n",
      "           40: 'Yes',\n",
      "           44: 'Yes',\n",
      "           48: 'No',\n",
      "           50: 'No',\n",
      "           52: 'No',\n",
      "           61: 'No',\n",
      "           66: 'No',\n",
      "           69: 'No',\n",
      "           70: 'Yes',\n",
      "           73: 'Yes',\n",
      "           75: 'Yes',\n",
      "           80: 'Yes',\n",
      "           83: 'No',\n",
      "           86: 'No',\n",
      "           91: 'No',\n",
      "           95: 'No',\n",
      "           98: 'No'}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Entropy of the target attribute values\n",
    "def find_entropy(df):\n",
    "    target = df.keys()[-1]  # The last dataframe column is the target attribute (playGolf)\n",
    "    entropy = 0\n",
    "    values = df[target].unique()\n",
    "    # for each value in the target playGolf attribute values\n",
    "    for value in values:\n",
    "        # ratio of values occurring and entropy\n",
    "        fraction = df[target].value_counts()[value] / len(df[target])\n",
    "        entropy += -fraction * np.log2(fraction)\n",
    "    return entropy\n",
    "\n",
    "# Entropy of attribute values\n",
    "def find_entropy_attribute(df, attribute):\n",
    "    target = df.keys()[-1]\n",
    "    target_variables = df[target].unique()  \n",
    "    # unique values in target playGolf attribute (Yes, No)\n",
    "    variables = df[attribute].unique() # Identify Sunny, Overcast, Rainy\n",
    "    # attribute entropy\n",
    "    # Variables=[sunny, sunny....5, overcast1.....overcast4, Rainy1...Ra5 ]\n",
    "    entropy2 = 0\n",
    "    # for each attribute value in attribute values\n",
    "    for variable in variables:\n",
    "        \n",
    "        # value entropy\n",
    "        entropy = 0\n",
    "        # for each target value in target values (yes/no)\n",
    "        for target_variable in target_variables:\n",
    "            \n",
    "   # frequency of attribute and target values (boolean indexing, pandas dataframe filtering)\n",
    "          num = len(df[attribute][df[attribute] == variable][df[target] == target_variable])\n",
    "          den = len(df[attribute][df[attribute] == variable])\n",
    "          fraction = num / (den + eps)\n",
    "          entropy += -fraction * np.log2(fraction + eps)\n",
    "        fraction2 = den / len(df)\n",
    "        entropy2 += -fraction2 * entropy\n",
    "    return abs(entropy2)\n",
    "\n",
    "\n",
    "def bestClassifier(df):\n",
    "    # Entropy_att = []\n",
    "    # information gain array for all attributes\n",
    "    IG = []\n",
    "    # for all attributes excluding target\n",
    "    for key in df.keys()[:-1]:\n",
    "        # Entropy_att.append(find_entropy_attribute(df,key))\n",
    "        # calculate and record information gain value\n",
    "        IG.append(find_entropy(df) - find_entropy_attribute(df, key)) \n",
    "    return df.keys()[:-1][np.argmax(IG)]  \n",
    "\n",
    "\n",
    "\n",
    "# function for creating subtable\n",
    "def get_subtable(df, node, value):\n",
    "    return df[df[node] == value].reset_index(drop=True)\n",
    "def ID3split(df, tree=None):\n",
    "    target = df.keys()[-1]\n",
    "    \n",
    "    # Here we build our decision tree\n",
    "    # Get attribute with maximum information gain\n",
    "    node = bestClassifier(df) # 0.247\n",
    "    # Get distinct value of that attribute e.g Salary is node and Low,Med and High are values\n",
    "    attributeValues = np.unique(df[node])\n",
    "    # Create an empty dictionary to create tree (recursive-friendly definition)\n",
    "    if tree is None:               #  Outlook ->root node attribute\n",
    "        tree = {}\n",
    "        tree[node] = {}\n",
    "    # following loop recursively calls ID3split to create and add to the tree\n",
    "    # it runs till the tree is pure (leaf (result) node branches are added to the tree)\n",
    "    for value in attributeValues:\n",
    "        \n",
    "        # get the subtable from current node based on the value\n",
    "        subtable = get_subtable(df, node, value)\n",
    "        # get the most common target value in the subtable\n",
    "        targetValues, counts = np.unique(subtable[target], return_counts=True)\n",
    "        \n",
    "        # if the subtable is empty, assign the leaf node to the most common target value\n",
    "        if len(counts) == 1:\n",
    "            tree[node][value] = targetValues[0]\n",
    "        \n",
    "        else:\n",
    "            # recursively call ID3 to create subtrees\n",
    "            tree[node][value] = ID3split(subtable)  # Calling the function recursively\n",
    "    return tree\n",
    "\n",
    "decisionTree = ID3split(data)\n",
    "pprint.pprint(decisionTree)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
