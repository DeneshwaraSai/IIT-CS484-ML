{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  4. -3.]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def load_data(filename):\n",
    "    data = pd.read_csv(filename)\n",
    "    X = data.iloc[:, :-1].values\n",
    "    y = np.where(data.iloc[:, -1] == 'Positive', 1, 0)\n",
    "    return X, y\n",
    "\n",
    "def my_perceptron(X, y, threshold=0.01, max_iter=1000):\n",
    "    n_samples, n_features = X.shape\n",
    "    weights = np.zeros(n_features)\n",
    "    bias = 0\n",
    "    misclassified = True\n",
    "    iteration = 0\n",
    "    \n",
    "    # print(weights)\n",
    "\n",
    "    while misclassified and iteration < max_iter:\n",
    "        misclassified = False\n",
    "        for i in range(n_samples):\n",
    "            if np.dot(X[i], weights) + bias <= 0:\n",
    "                weights += X[i] * y[i]\n",
    "                bias += y[i]\n",
    "                misclassified = True\n",
    "        iteration += 1\n",
    "        # print(X[i] , \" -> \" , weights)\n",
    "\n",
    "    # print(weights)\n",
    "    return weights, bias\n",
    "\n",
    "def plot_separator(X, y, weights, bias):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # Plot data points\n",
    "    positive_indices = (y == 1)\n",
    "    negative_indices = (y == 0)\n",
    "    ax.scatter(X[positive_indices][:,0], X[positive_indices][:,1], X[positive_indices][:,2], c='b', label='Positive')\n",
    "    ax.scatter(X[negative_indices][:,0], X[negative_indices][:,1], X[negative_indices][:,2], c='r', label='Negative')\n",
    "\n",
    "    # Plot separator\n",
    "    xx, yy = np.meshgrid(range(-2, 3), range(-2, 3))\n",
    "    zz = (-weights[0] * xx - weights[1] * yy - bias) / weights[2]\n",
    "    ax.plot_surface(xx, yy, zz, alpha=0.5)\n",
    "\n",
    "    ax.set_xlabel('X1')\n",
    "    ax.set_ylabel('X2')\n",
    "    ax.set_zlabel('X3')\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load data\n",
    "    X, y = load_data('lab02_dataset_1.csv')\n",
    "\n",
    "    # print(y)\n",
    "    # X = np.array([[1, 2], [2, 3], [2, 1], [3, 0]])\n",
    "    # y = np.array([1, 1, 0, 0])\n",
    "\n",
    "    X = np.array([[1, 2, 1] , [1, -2, 1] , [3, 1, 2], [2, 3, 2] , [-1, 2, -2] , [-1, -2, 4] , [1, -3, -3] , [-2, 4, -2] , [4, 1, 3] , [-1, 2, -4]])\n",
    "    y = np.array([1,0,0,1,1,0,0,1,0,1])\n",
    "\n",
    "    # Apply perceptron algorithm\n",
    "    weights, bias = my_perceptron(X, y)\n",
    "    print(weights)\n",
    "    print(bias)\n",
    "    # Plot dataset and separator\n",
    "    # plot_separator(X, y, weights, bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts: [1641. 2931.]\n",
      "Probabilities P(Yj): [0.35892388 0.64107612]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2,20) (2,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 39\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProbabilities P(Yj):\u001b[39m\u001b[38;5;124m\"\u001b[39m, class_probabilities)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# 2. Output P(Xi|Yj) along with their counts\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Calculate feature probabilities\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m feature_probabilities \u001b[38;5;241m=\u001b[39m (\u001b[43mfeature_counts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mclass_counts\u001b[49m)\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature Counts (P(Xi|Yj)):\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(pd\u001b[38;5;241m.\u001b[39mDataFrame(feature_counts, columns\u001b[38;5;241m=\u001b[39mX_encoded\u001b[38;5;241m.\u001b[39mcolumns))\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2,20) (2,) "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have your data loaded into a DataFrame called 'data'\n",
    "data = pd.read_excel('lab02_dataset_2.xlsx', engine='openpyxl')\n",
    "\n",
    "# Dropping missing values\n",
    "data_complete = data.dropna()\n",
    "\n",
    "# Extracting features and target variable\n",
    "X = data_complete[['OCCUPATION', 'EDUCATION', 'CAR_TYPE']]\n",
    "y = data_complete['CAR_USE']\n",
    "\n",
    "# Converting categorical variables to numerical using label encoding\n",
    "X_encoded = pd.get_dummies(X)\n",
    "\n",
    "# Splitting the data into train and test sets (assuming you have test data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Calculate feature counts\n",
    "feature_counts = np.array([np.bincount(X_train[c]) for c in X_train.columns])\n",
    "\n",
    "# Training Naive Bayes model with Laplace smoothing of 0.01\n",
    "naive_bayes_model = CategoricalNB(alpha=0.01)\n",
    "naive_bayes_model.fit(X_train, y_train)\n",
    "\n",
    "# 1. Output Class counts and Probabilities P(Yj)\n",
    "class_counts = naive_bayes_model.class_count_\n",
    "class_probabilities = class_counts / np.sum(class_counts)\n",
    "\n",
    "print(\"Class counts:\", class_counts)\n",
    "print(\"Probabilities P(Yj):\", class_probabilities)\n",
    "\n",
    "# 2. Output P(Xi|Yj) along with their counts\n",
    "# Calculate feature probabilities\n",
    "feature_probabilities = (feature_counts.T / class_counts).T\n",
    "\n",
    "print(\"Feature Counts (P(Xi|Yj)):\")\n",
    "print(pd.DataFrame(feature_counts, columns=X_encoded.columns))\n",
    "print(\"Feature Probabilities (P(Xi|Yj)):\")\n",
    "print(pd.DataFrame(feature_probabilities, columns=X_encoded.columns))\n",
    "\n",
    "# 3. Predict probabilities for the test cases\n",
    "test_case_1 = [[0, 1, 0]]  # [Blue Collar, PhD, SUV]\n",
    "test_case_2 = [[2, 0, 1]]  # [Manager, Below High School, Sports Car]\n",
    "\n",
    "probabilities_test_case_1 = naive_bayes_model.predict_proba(test_case_1)\n",
    "probabilities_test_case_2 = naive_bayes_model.predict_proba(test_case_2)\n",
    "\n",
    "print(\"Car Usage probabilities for Test Case 1:\", probabilities_test_case_1)\n",
    "print(\"Car Usage probabilities for Test Case 2:\", probabilities_test_case_2)\n",
    "\n",
    "# 4. Generate histogram of predicted probabilities of CAR_USE = Private\n",
    "predicted_probabilities_private = naive_bayes_model.predict_proba(X_test)[:, 1]\n",
    "plt.hist(predicted_probabilities_private, bins=np.arange(0, 1.05, 0.05), density=True)\n",
    "plt.xlabel('Predicted Probability of CAR_USE = Private')\n",
    "plt.ylabel('Proportion of Observations')\n",
    "plt.title('Histogram of Predicted Probabilities')\n",
    "plt.show()\n",
    "\n",
    "# 5. Calculate misclassification rate\n",
    "misclassification_rate = 1 - naive_bayes_model.score(X_test, y_test)\n",
    "print(\"Misclassification rate:\", misclassification_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
